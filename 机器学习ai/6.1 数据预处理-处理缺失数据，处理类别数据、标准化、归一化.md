[TOC]

## 1. 处理缺失数据
一般有2种方式：
### 1.1 赋值
如果数据量比较少，或者不想删除，通过使用其他列值求**平均**的方式.

对列值求索引，是因为每一列属于一个特征，是一类值。

代码如下：
```python
from sklearn.preprocessing import Imputer

imr = Imputer(missing_values='NaN', strategy='mean', axis=0)
imr = imr.fit(df.values)
imputed_data = imr.transform(df.values)
imputed_data
```

### 1.2 删除
如果数据量特别大的时候，可以通过删除的方式，因为大数据时代，很多时候损失少量数据并不要紧。

代码如下：
```python
# 删除包含缺失数据的行
df.dropna(axis=0)

# In[5]:
# 删除包含缺失数据的列
df.dropna(axis=1)

# In[6]:
# 新的测试数据
csv_data2 = '''A,B,C,D
1.0,2.0,,
,,,
10.0,11.0,12.0,'''

# 显示数据
df2 = pd.read_csv(StringIO(csv_data2))
# 以表格显示显示
df2

# In[7]:
# 其他的处理方法
# 如果一行全是NaN才删除
df2.dropna(how='all')  

# In[8]:
# thresh=3,那么一行当中至少有三个数值时才将其保留
df2.dropna(axis=0,thresh=3)

# In[9]:
# 缺省是对行进行处理。thresh=3,那么一行当中至少有三个数值时才将其保留
df2.dropna(thresh=3)

# In[10]:
# thresh=2,那么一列当中至少有两个数值时才将其保留
df2.dropna(axis=1,thresh=2)

# In[11]:
# only drop rows where NaN appear in specific columns (here: 'C')
# 只是将C列中有NaN的行删除掉
df2.dropna(subset=['C'])

# In[12]:
# 重新显示第一组数据集
df.values
```

## 2. 处理类别数据

类别数据指的**是非数据值**的数据，比如颜色：green、red、blue等，衣服尺码：M、L、XL、XXL。

> **原则：将类别数据转化为数值类型**

 **color** | **size** | **price** | **classlabel**
---|--- | ---- | ----
green | M | 10.1 | class1
red | L | 9.2 | class1
blue | XL | 15.7 | class2

### 2.1 直接转化为数值

size(衣服尺寸)：可以映射到1，2，3，因为尺寸有大小之分，可以比较的，数值的大小可以表现这个特性。

> 转化的数值，要根据该特征固有的属性。某些时候跟行业知识有关。

### 2.2 ONE-HOT编码

当某些属性并不具有相互关系时，比如颜色，使用ONE-HOT编码方式。

![Onehot](D4A3D42A853348E79C6AFD0D8AEB8889)

```python
import pandas as pd

df = pd.DataFrame([['green', 'M', 10.1, 'class1'],
                   ['red', 'L', 13.5, 'class2'],
                   ['blue', 'XL', 15.3, 'class1']])

df.columns = ['color', 'size', 'price', 'classlabel']
# 显示举例数据
df_origin = df
df

# 映射size数据
size_mapping = {'XL': 3,
                'L': 2,
                'M': 1}

df['size'] = df['size'].map(size_mapping)
df

import numpy as np
# 将类别设置为0和1
class_mapping = {label: idx for idx, label in enumerate(np.unique(df['classlabel']))}
class_mapping

# 类别数据映射到整数
df['classlabel'] = df['classlabel'].map(class_mapping)
df

# 仅仅显示二维特征数据
X = df[['color', 'size', 'price']].values
X

# 首先将color颜色数据转为数值
from sklearn.preprocessing import LabelEncoder
color_le = LabelEncoder()
X[:, 0] = color_le.fit_transform(X[:, 0])
X

# In[20]:
# 将color颜色的数值转为one-hot数据
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(categorical_features=[0])
ohe.fit_transform(X).toarray()

# In[21]:
# 再次显示表格内容数据
df

# In[22]:
# 使用另一个方法转0ne-hot：pandas模块的get_dummies方法
pd.get_dummies(df[['price', 'color', 'size']])
```

## 3. 划分数据集

- 很多时候，我们只是拥有一个数据集，对于未来要测试要发生的数据并不知道。
- 一般来说，对于一个已知的数据集，一部分数据用于训练模型，而另一部分用于测试模型是否有效。
- 常见的划分比例是8：2或者7：3，前面是训练集，后面是测试集。

> 分层采样，保持每种类别数据的样本一致。

代码如下：

```python
# 将已知的数据化为训练集和测试集
from sklearn.model_selection import train_test_split

X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values

X_train, X_test, y_train, y_test =  train_test_split(X, y, 
                     test_size=0.3, 
                     random_state=0, 
                     stratify=y)
X.shape,X_train.shape,X_test.shape
```


## 4. 数据标准化、归一化

### 4.1 WHY
- 样本不同的特征/属性所在的数值范围差异巨大，导致训**练不收敛**或其他问题.
- 所有数据在相同的取值空间更容易处理，方便模型的统一化和规范化。
- 更容易发现数据的本质规律。


样本 | 特征1 | 特征2
---|--- |---
0 | 10000 | 1
1 | 20000 | 2
2 | 30000 | 3
3 | 40000 | 4
4 | 50000 | 5


### 4.2 归一化

将数据缩放到[0,1]的范围：公式
```math
x = (x-min)/(max-min)
```

![1](7F0AA903C4CA44DA805F54AD6928BADC)

> 训练和测试数据一般都要归一化，min和max一定是训练集的min和max，x分别是训练和测试集的

> 代码中体现在测试集只有transform操作，而训练集多了一个fit操作，这个fit操作就是从训练集中得到min和max两个参数的过程，这个min和max同时会用到
测试集，所以测试集没有这个步骤。对于下面的标准化一样道理，从训练数据中计算出均值𝜇和标准差
𝜎，也应用到测试数据。
WHY？因为我们基于的假设是：**训练数据与数据整体的分布是一致**的，模型来自训练数据。

代码如下：
```python
from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
X_train_norm = mms.fit_transform(X_train)
X_test_norm = mms.transform(X_test)
X_train_norm[:5,0:3]
```

### 4.3 标准化

数据标准化方法经过处理后数据符合标准正态分布，即均值为0，标准差为1
转化函数为：x =(x - 𝜇)/𝜎

```python
from sklearn.preprocessing import StandardScaler
stdsc = StandardScaler()
X_train_std = stdsc.fit_transform(X_train)
X_test_std = stdsc.transform(X_test)
X_test_std[:5,0:3]
```






