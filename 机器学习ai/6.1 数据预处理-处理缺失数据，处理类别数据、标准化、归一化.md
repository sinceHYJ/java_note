[TOC]

## 1. å¤„ç†ç¼ºå¤±æ•°æ®
ä¸€èˆ¬æœ‰2ç§æ–¹å¼ï¼š
### 1.1 èµ‹å€¼
å¦‚æœæ•°æ®é‡æ¯”è¾ƒå°‘ï¼Œæˆ–è€…ä¸æƒ³åˆ é™¤ï¼Œé€šè¿‡ä½¿ç”¨å…¶ä»–åˆ—å€¼æ±‚**å¹³å‡**çš„æ–¹å¼.

å¯¹åˆ—å€¼æ±‚ç´¢å¼•ï¼Œæ˜¯å› ä¸ºæ¯ä¸€åˆ—å±äºä¸€ä¸ªç‰¹å¾ï¼Œæ˜¯ä¸€ç±»å€¼ã€‚

ä»£ç å¦‚ä¸‹ï¼š
```python
from sklearn.preprocessing import Imputer

imr = Imputer(missing_values='NaN', strategy='mean', axis=0)
imr = imr.fit(df.values)
imputed_data = imr.transform(df.values)
imputed_data
```

### 1.2 åˆ é™¤
å¦‚æœæ•°æ®é‡ç‰¹åˆ«å¤§çš„æ—¶å€™ï¼Œå¯ä»¥é€šè¿‡åˆ é™¤çš„æ–¹å¼ï¼Œå› ä¸ºå¤§æ•°æ®æ—¶ä»£ï¼Œå¾ˆå¤šæ—¶å€™æŸå¤±å°‘é‡æ•°æ®å¹¶ä¸è¦ç´§ã€‚

ä»£ç å¦‚ä¸‹ï¼š
```python
# åˆ é™¤åŒ…å«ç¼ºå¤±æ•°æ®çš„è¡Œ
df.dropna(axis=0)

# In[5]:
# åˆ é™¤åŒ…å«ç¼ºå¤±æ•°æ®çš„åˆ—
df.dropna(axis=1)

# In[6]:
# æ–°çš„æµ‹è¯•æ•°æ®
csv_data2 = '''A,B,C,D
1.0,2.0,,
,,,
10.0,11.0,12.0,'''

# æ˜¾ç¤ºæ•°æ®
df2 = pd.read_csv(StringIO(csv_data2))
# ä»¥è¡¨æ ¼æ˜¾ç¤ºæ˜¾ç¤º
df2

# In[7]:
# å…¶ä»–çš„å¤„ç†æ–¹æ³•
# å¦‚æœä¸€è¡Œå…¨æ˜¯NaNæ‰åˆ é™¤
df2.dropna(how='all')  

# In[8]:
# thresh=3,é‚£ä¹ˆä¸€è¡Œå½“ä¸­è‡³å°‘æœ‰ä¸‰ä¸ªæ•°å€¼æ—¶æ‰å°†å…¶ä¿ç•™
df2.dropna(axis=0,thresh=3)

# In[9]:
# ç¼ºçœæ˜¯å¯¹è¡Œè¿›è¡Œå¤„ç†ã€‚thresh=3,é‚£ä¹ˆä¸€è¡Œå½“ä¸­è‡³å°‘æœ‰ä¸‰ä¸ªæ•°å€¼æ—¶æ‰å°†å…¶ä¿ç•™
df2.dropna(thresh=3)

# In[10]:
# thresh=2,é‚£ä¹ˆä¸€åˆ—å½“ä¸­è‡³å°‘æœ‰ä¸¤ä¸ªæ•°å€¼æ—¶æ‰å°†å…¶ä¿ç•™
df2.dropna(axis=1,thresh=2)

# In[11]:
# only drop rows where NaN appear in specific columns (here: 'C')
# åªæ˜¯å°†Cåˆ—ä¸­æœ‰NaNçš„è¡Œåˆ é™¤æ‰
df2.dropna(subset=['C'])

# In[12]:
# é‡æ–°æ˜¾ç¤ºç¬¬ä¸€ç»„æ•°æ®é›†
df.values
```

## 2. å¤„ç†ç±»åˆ«æ•°æ®

ç±»åˆ«æ•°æ®æŒ‡çš„**æ˜¯éæ•°æ®å€¼**çš„æ•°æ®ï¼Œæ¯”å¦‚é¢œè‰²ï¼šgreenã€redã€blueç­‰ï¼Œè¡£æœå°ºç ï¼šMã€Lã€XLã€XXLã€‚

> **åŸåˆ™ï¼šå°†ç±»åˆ«æ•°æ®è½¬åŒ–ä¸ºæ•°å€¼ç±»å‹**

 **color** | **size** | **price** | **classlabel**
---|--- | ---- | ----
green | M | 10.1 | class1
red | L | 9.2 | class1
blue | XL | 15.7 | class2

### 2.1 ç›´æ¥è½¬åŒ–ä¸ºæ•°å€¼

size(è¡£æœå°ºå¯¸)ï¼šå¯ä»¥æ˜ å°„åˆ°1ï¼Œ2ï¼Œ3ï¼Œå› ä¸ºå°ºå¯¸æœ‰å¤§å°ä¹‹åˆ†ï¼Œå¯ä»¥æ¯”è¾ƒçš„ï¼Œæ•°å€¼çš„å¤§å°å¯ä»¥è¡¨ç°è¿™ä¸ªç‰¹æ€§ã€‚

> è½¬åŒ–çš„æ•°å€¼ï¼Œè¦æ ¹æ®è¯¥ç‰¹å¾å›ºæœ‰çš„å±æ€§ã€‚æŸäº›æ—¶å€™è·Ÿè¡Œä¸šçŸ¥è¯†æœ‰å…³ã€‚

### 2.2 ONE-HOTç¼–ç 

å½“æŸäº›å±æ€§å¹¶ä¸å…·æœ‰ç›¸äº’å…³ç³»æ—¶ï¼Œæ¯”å¦‚é¢œè‰²ï¼Œä½¿ç”¨ONE-HOTç¼–ç æ–¹å¼ã€‚

![Onehot](D4A3D42A853348E79C6AFD0D8AEB8889)

```python
import pandas as pd

df = pd.DataFrame([['green', 'M', 10.1, 'class1'],
                   ['red', 'L', 13.5, 'class2'],
                   ['blue', 'XL', 15.3, 'class1']])

df.columns = ['color', 'size', 'price', 'classlabel']
# æ˜¾ç¤ºä¸¾ä¾‹æ•°æ®
df_origin = df
df

# æ˜ å°„sizeæ•°æ®
size_mapping = {'XL': 3,
                'L': 2,
                'M': 1}

df['size'] = df['size'].map(size_mapping)
df

import numpy as np
# å°†ç±»åˆ«è®¾ç½®ä¸º0å’Œ1
class_mapping = {label: idx for idx, label in enumerate(np.unique(df['classlabel']))}
class_mapping

# ç±»åˆ«æ•°æ®æ˜ å°„åˆ°æ•´æ•°
df['classlabel'] = df['classlabel'].map(class_mapping)
df

# ä»…ä»…æ˜¾ç¤ºäºŒç»´ç‰¹å¾æ•°æ®
X = df[['color', 'size', 'price']].values
X

# é¦–å…ˆå°†coloré¢œè‰²æ•°æ®è½¬ä¸ºæ•°å€¼
from sklearn.preprocessing import LabelEncoder
color_le = LabelEncoder()
X[:, 0] = color_le.fit_transform(X[:, 0])
X

# In[20]:
# å°†coloré¢œè‰²çš„æ•°å€¼è½¬ä¸ºone-hotæ•°æ®
from sklearn.preprocessing import OneHotEncoder
ohe = OneHotEncoder(categorical_features=[0])
ohe.fit_transform(X).toarray()

# In[21]:
# å†æ¬¡æ˜¾ç¤ºè¡¨æ ¼å†…å®¹æ•°æ®
df

# In[22]:
# ä½¿ç”¨å¦ä¸€ä¸ªæ–¹æ³•è½¬0ne-hotï¼špandasæ¨¡å—çš„get_dummiesæ–¹æ³•
pd.get_dummies(df[['price', 'color', 'size']])
```

## 3. åˆ’åˆ†æ•°æ®é›†

- å¾ˆå¤šæ—¶å€™ï¼Œæˆ‘ä»¬åªæ˜¯æ‹¥æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œå¯¹äºæœªæ¥è¦æµ‹è¯•è¦å‘ç”Ÿçš„æ•°æ®å¹¶ä¸çŸ¥é“ã€‚
- ä¸€èˆ¬æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªå·²çŸ¥çš„æ•°æ®é›†ï¼Œä¸€éƒ¨åˆ†æ•°æ®ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œè€Œå¦ä¸€éƒ¨åˆ†ç”¨äºæµ‹è¯•æ¨¡å‹æ˜¯å¦æœ‰æ•ˆã€‚
- å¸¸è§çš„åˆ’åˆ†æ¯”ä¾‹æ˜¯8ï¼š2æˆ–è€…7ï¼š3ï¼Œå‰é¢æ˜¯è®­ç»ƒé›†ï¼Œåé¢æ˜¯æµ‹è¯•é›†ã€‚

> åˆ†å±‚é‡‡æ ·ï¼Œä¿æŒæ¯ç§ç±»åˆ«æ•°æ®çš„æ ·æœ¬ä¸€è‡´ã€‚

ä»£ç å¦‚ä¸‹ï¼š

```python
# å°†å·²çŸ¥çš„æ•°æ®åŒ–ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
from sklearn.model_selection import train_test_split

X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values

X_train, X_test, y_train, y_test =  train_test_split(X, y, 
                     test_size=0.3, 
                     random_state=0, 
                     stratify=y)
X.shape,X_train.shape,X_test.shape
```


## 4. æ•°æ®æ ‡å‡†åŒ–ã€å½’ä¸€åŒ–

### 4.1 WHY
- æ ·æœ¬ä¸åŒçš„ç‰¹å¾/å±æ€§æ‰€åœ¨çš„æ•°å€¼èŒƒå›´å·®å¼‚å·¨å¤§ï¼Œå¯¼è‡´è®­**ç»ƒä¸æ”¶æ•›**æˆ–å…¶ä»–é—®é¢˜.
- æ‰€æœ‰æ•°æ®åœ¨ç›¸åŒçš„å–å€¼ç©ºé—´æ›´å®¹æ˜“å¤„ç†ï¼Œæ–¹ä¾¿æ¨¡å‹çš„ç»Ÿä¸€åŒ–å’Œè§„èŒƒåŒ–ã€‚
- æ›´å®¹æ˜“å‘ç°æ•°æ®çš„æœ¬è´¨è§„å¾‹ã€‚


æ ·æœ¬ | ç‰¹å¾1 | ç‰¹å¾2
---|--- |---
0 | 10000 | 1
1 | 20000 | 2
2 | 30000 | 3
3 | 40000 | 4
4 | 50000 | 5


### 4.2 å½’ä¸€åŒ–

å°†æ•°æ®ç¼©æ”¾åˆ°[0,1]çš„èŒƒå›´ï¼šå…¬å¼
```math
x = (x-min)/(max-min)
```

![1](7F0AA903C4CA44DA805F54AD6928BADC)

> è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸€èˆ¬éƒ½è¦å½’ä¸€åŒ–ï¼Œminå’Œmaxä¸€å®šæ˜¯è®­ç»ƒé›†çš„minå’Œmaxï¼Œxåˆ†åˆ«æ˜¯è®­ç»ƒå’Œæµ‹è¯•é›†çš„

> ä»£ç ä¸­ä½“ç°åœ¨æµ‹è¯•é›†åªæœ‰transformæ“ä½œï¼Œè€Œè®­ç»ƒé›†å¤šäº†ä¸€ä¸ªfitæ“ä½œï¼Œè¿™ä¸ªfitæ“ä½œå°±æ˜¯ä»è®­ç»ƒé›†ä¸­å¾—åˆ°minå’Œmaxä¸¤ä¸ªå‚æ•°çš„è¿‡ç¨‹ï¼Œè¿™ä¸ªminå’ŒmaxåŒæ—¶ä¼šç”¨åˆ°
æµ‹è¯•é›†ï¼Œæ‰€ä»¥æµ‹è¯•é›†æ²¡æœ‰è¿™ä¸ªæ­¥éª¤ã€‚å¯¹äºä¸‹é¢çš„æ ‡å‡†åŒ–ä¸€æ ·é“ç†ï¼Œä»è®­ç»ƒæ•°æ®ä¸­è®¡ç®—å‡ºå‡å€¼ğœ‡å’Œæ ‡å‡†å·®
ğœï¼Œä¹Ÿåº”ç”¨åˆ°æµ‹è¯•æ•°æ®ã€‚
WHYï¼Ÿå› ä¸ºæˆ‘ä»¬åŸºäºçš„å‡è®¾æ˜¯ï¼š**è®­ç»ƒæ•°æ®ä¸æ•°æ®æ•´ä½“çš„åˆ†å¸ƒæ˜¯ä¸€è‡´**çš„ï¼Œæ¨¡å‹æ¥è‡ªè®­ç»ƒæ•°æ®ã€‚

ä»£ç å¦‚ä¸‹ï¼š
```python
from sklearn.preprocessing import MinMaxScaler
mms = MinMaxScaler()
X_train_norm = mms.fit_transform(X_train)
X_test_norm = mms.transform(X_test)
X_train_norm[:5,0:3]
```

### 4.3 æ ‡å‡†åŒ–

æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•ç»è¿‡å¤„ç†åæ•°æ®ç¬¦åˆæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œå³å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1
è½¬åŒ–å‡½æ•°ä¸ºï¼šx =(x - ğœ‡)/ğœ

```python
from sklearn.preprocessing import StandardScaler
stdsc = StandardScaler()
X_train_std = stdsc.fit_transform(X_train)
X_test_std = stdsc.transform(X_test)
X_test_std[:5,0:3]
```






